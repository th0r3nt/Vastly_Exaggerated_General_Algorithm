
========================================
# Содержимое файла: assistant_background_tasks/background_tasks.py
========================================

import wmi
from datetime import datetime
import logging
import sys
import os
import requests
from datetime import datetime  # noqa: F811

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from assistant_general.logger_config import setup_logger  # noqa: E402

setup_logger()
logger = logging.getLogger(__name__)

# ЧТО НУЖНО РЕАЛИЗОВАТЬ:
# Задачи, выполняемые только ОДИН раз в день 
# "morning_briefing": - ежедневный брифинг с погодой, новыми новостями
# "file_cleanup": - очистка ненужный файлов каждый вечер-ночь
# "system_health_check": - проверка логов нагрузки системы каждый вечер
# "social_digest": - парсит соцсети (например, телеграм-канал) и выдает краткую сводку самых важных новостей от контактов или каналов    

# Задачи, выполняемые ЧАЩЕ раза в день
# "arxiv_parse": - парсинг научных статей каждые 6 часов.
# "system_monitor_snapshot": Сохранение "снимка" состояния системы (CPU, RAM) каждые 5 минут для построения исторических графиков (обязательно для system_health_check)






========================================
# Содержимое файла: assistant_brain/added_skills.py
========================================

# added_skills.py

# 1. ИМПОРТ СХЕМЫ НОВОГО ИНСТРУМЕНТА
from assistant_tools.skills_diagrams import (
    get_weather_scheme, search_in_google_scheme, get_date_scheme, get_time_scheme, make_screenshot_scheme, save_to_memory_scheme, lock_pc_scheme,
    get_windows_layout_scheme, move_mouse_scheme, current_mouse_coordinates_scheme, click_mouse_scheme, scroll_mouse_scheme, drag_mouse_scheme,
    press_hotkey_scheme, copy_to_clipboard_scheme, write_text_scheme, system_command_scheme, get_filtered_processes_scheme, currently_open_windows_scheme,
    manage_window_scheme, open_program_scheme, kill_process_by_name_scheme, get_system_volume_scheme, set_system_volume_scheme, decrease_volume_scheme,
    increase_volume_scheme, get_habr_news_scheme, get_system_metrics_scheme,
)
from assistant_tools.music_skills_diagrams import ( # Отдельные музыкальные навыки
    music_play_random_scheme, music_pause_playback_scheme, music_resume_playback_scheme, music_play_next_track_scheme,
    music_play_previous_track_scheme, music_clear_playlist_scheme, music_play_playlist_scheme, music_play_track_scheme,
    music_play_random_album_scheme, 
)

import assistant_tools.skills
import assistant_tools.music_skills

# 2. РЕГИСТРАЦИЯ JSON-СХЕМЫ НОВОГО ИНСТРУМЕНТА ДЛЯ FUNCTION CALLING НЕЙРОСЕТИ (Чтобы нейросеть читала описание навыков и могла понимать, что и с какими параметрами вызывать навыки)
function_declarations = [
    # БАЗОВЫЕ НАВЫКИ
    get_weather_scheme, 
    search_in_google_scheme, 
    get_date_scheme, 
    get_time_scheme, 
    make_screenshot_scheme, 
    save_to_memory_scheme, 
    lock_pc_scheme,
    get_habr_news_scheme,
    get_system_metrics_scheme,

    # УПРАВЛЕНИЕ СИСТЕМНЫМ ЗВУКОМ
    get_system_volume_scheme,
    set_system_volume_scheme, 
    decrease_volume_scheme,
    increase_volume_scheme,

    # НАВЫКИ, КОТОРЫЕ УПРАВЛЯЮТ МЫШЬЮ И КЛАВИАТУРОЙ
    get_windows_layout_scheme, 
    move_mouse_scheme, 
    current_mouse_coordinates_scheme, 
    click_mouse_scheme, 
    scroll_mouse_scheme, 
    drag_mouse_scheme,
    press_hotkey_scheme, 
    copy_to_clipboard_scheme, 
    write_text_scheme, 
    system_command_scheme, 

    # НАВЫКИ, СВЯЗАННЫЕ С ВЗАИМОДЕЙСТВИЕМ С ПРИЛОЖЕНИЯМИ И ОКНАМИ
    get_filtered_processes_scheme, 
    currently_open_windows_scheme,
    manage_window_scheme, 
    open_program_scheme, 
    kill_process_by_name_scheme, 

    # НАВЫКИ, СВЯЗАННЫЕ С МУЗЫКОЙ ИЗ FOOBAR2000
    music_play_random_scheme, 
    music_pause_playback_scheme, 
    music_resume_playback_scheme, 
    music_play_next_track_scheme,
    music_play_previous_track_scheme, 
    music_clear_playlist_scheme, 
    music_play_playlist_scheme, 
    music_play_track_scheme,
    music_play_random_album_scheme,
    
]

# 3. УКАЗАНИЕ, КАКОЙ НАВЫК ИСПОЛЬЗОВАТЬ (НЕЙРОСЕТЬ БУДЕТ ВЫЗЫВАТЬ КЛЮЧИ (возможно также будет передавать что-либо), И В ДАННОМ СЛУЧАЕ ЗНАЧЕНИЕ КЛЮЧА АКТИВИРУЕТ СООВЕТСТВУЮЩИЙ НАВЫК ДЛЯ ЭТОГО КЛЮЧА)
skills_registry = {
    # БАЗОВЫЕ НАВЫКИ
    "get_weather": assistant_tools.skills.get_weather, # Правильные ключи брать из файла skills_diagrams.py по ключу "name"
    "search_in_google": assistant_tools.skills.search_in_google,
    "get_date": assistant_tools.skills.get_date,
    "get_time": assistant_tools.skills.get_time,
    "make_screenshot": assistant_tools.skills.make_screenshot,
    "save_to_memory": assistant_tools.skills.save_to_memory,
    "lock_pc": assistant_tools.skills.lock_pc,
    "get_habr_news": assistant_tools.skills.get_habr_news,
    "get_system_metrics": assistant_tools.skills.get_system_metrics,

    # УПРАВЛЕНИЕ СИСТЕМНЫМ ЗВУКОМ
    "get_system_volume": assistant_tools.skills.get_system_volume,
    "set_system_volume": assistant_tools.skills.set_system_volume,
    "decrease_volume": assistant_tools.skills.decrease_volume,
    "increase_volume": assistant_tools.skills.increase_volume,

    # НАВЫКИ, КОТОРЫЕ УПРАВЛЯЮТ МЫШЬЮ И КЛАВИАТУРОЙ
    "get_windows_layout": assistant_tools.skills.get_windows_layout, 
    "move_mouse": assistant_tools.skills.move_mouse, 
    "current_mouse_coordinates": assistant_tools.skills.current_mouse_coordinates, 
    "click_mouse": assistant_tools.skills.click_mouse,
    "scroll_mouse": assistant_tools.skills.scroll_mouse, 
    "drag_mouse": assistant_tools.skills.drag_mouse, 
    "press_hotkey": assistant_tools.skills.press_hotkey,
    "copy_to_clipboard": assistant_tools.skills.copy_to_clipboard,
    "write_text": assistant_tools.skills.write_text,
    "system_command": assistant_tools.skills.system_command,

    # НАВЫКИ, СВЯЗАННЫЕ С ВЗАИМОДЕЙСТВИЕМ С ПРИЛОЖЕНИЯМИ И ОКНАМИ
    "get_filtered_processes": assistant_tools.skills.get_filtered_processes,
    "currently_open_windows": assistant_tools.skills.currently_open_windows,
    "manage_window": assistant_tools.skills.manage_window,
    "open_program": assistant_tools.skills.open_program,
    "kill_process_by_name": assistant_tools.skills.kill_process_by_name,

    # НАВЫКИ, СВЯЗАННЫЕ С МУЗЫКОЙ ИЗ FOOBAR2000
    "music_play_random": assistant_tools.music_skills.music_play_random,
    "music_pause_playback": assistant_tools.music_skills.music_pause_playback,
    "music_resume_playback": assistant_tools.music_skills.music_resume_playback,
    "music_play_next_track": assistant_tools.music_skills.music_play_next_track,
    "music_play_previous_track": assistant_tools.music_skills.music_play_previous_track,
    "music_clear_playlist": assistant_tools.music_skills.music_clear_playlist,
    "music_play_playlist": assistant_tools.music_skills.music_play_playlist,
    "music_play_track": assistant_tools.music_skills.music_play_track,
    "music_play_random_album": assistant_tools.music_skills.music_play_random_album,
}



========================================
# Содержимое файла: assistant_brain/brain.py
========================================

# brain.py
import google.generativeai as genai
from google import genai  # noqa: F811
from google.genai import types
import threading
import os
import json
import datetime
from collections import deque
from dotenv import load_dotenv
from assistant_event_bus.event_bus import subscribe, publish
from assistant_tools.utils import play_sfx
import assistant_general.general_settings as general_settings
from systemic_tools.systemic_skills import read_json, write_json
from assistant_brain.added_skills import function_declarations, skills_registry # ДОБАВЛЯТЬ НОВЫЕ УМЕНИЯ В ЭТОТ ФАЙЛ

load_dotenv() # для загрузки API ключей из .env
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

client = genai.Client(api_key=GEMINI_API_KEY)
tools = types.Tool(function_declarations=function_declarations)
config = types.GenerateContentConfig(tools=[tools])

try:
    with open(general_settings.SHORT_TERM_MEMORY_PATH, 'r', encoding='utf-8') as f:
        short_term_memory = json.load(f)
except (FileNotFoundError, json.JSONDecodeError):
    print("Файла 'short_time_memory.ison' либо не существует, либо неверного формата. Создается новый в папку 'assistant_brain'.")
    # Если файла нет или он испорчен
    short_term_memory = []

def save_memory():
    with open(general_settings.SHORT_TERM_MEMORY_PATH, 'w', encoding='utf-8') as f:
        json.dump(list(short_term_memory), f, indent=4, ensure_ascii=False) # ensure_ascii чтобы русский текст от пользователя записывался корректно

short_term_memory = deque(short_term_memory, maxlen=general_settings.MAX_MEMORY) # Применяем deque к загруженному списку, чтобы снова включить лимит

def process_interaction(query, final_text_to_publish):
    current_date = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    short_term_memory.append(f"{current_date}, User: {query}")
    short_term_memory.append(f"{current_date}, V.E.G.A.: {final_text_to_publish}")
    save_memory() # Важно: Сохранять нужно либо после каждого добавления, либо при завершении программы

def run_gemini_task(**kwargs):
    query = kwargs.get('query')
    database_context = kwargs.get('database_context')
    try:
        response = client.models.generate_content(
        model=general_settings.MODEL_GEMINI,
        contents=general_settings.VEGA_PERSONALITY_CORE + 

        f"""Right now, your task is to maintain a conversation. 
        Don't deviate from your personality. BE BRIEF! Your name is feminine.

        Here's the relevant information from your database (memory). Use it to provide the most complete answer. If the information is irrelevant, you can ignore it.
        {database_context}


        Here's the previous dialogue (useful for context):
        {short_term_memory}


        User request: {query}
        V.E.G.A: 
        """,
        config=config,
        )

        function_calls = False
        results_of_tool_calls = [] # Полезно, если нужно несколько вызовов Function Calling

        text_parts = [] # Нужно, чтобы данные не терялись, если вызовов функций от нейросети не было

        # Проверяем наличие вызовов Function Calling
        for part in response.candidates[0].content.parts:
            if hasattr(part, 'function_call') and part.function_call is not None: # Если проверяемая часть - вызов функции
                function_call = part.function_call

                print(f"\nFunction to call: {function_call.name}")
                print(f"Arguments: {function_call.args}\n")

                function_calls = True

                function_to_call = skills_registry[function_call.name]
                result = function_to_call(**function_call.args) # result = например, результат вызова skills.get_weather(city_name="Липецк")"; ** распоковывает словарь в именованные аргументы

                history = response.candidates[0].content

                function_response_part = types.Part(
                    function_response=types.FunctionResponse(
                        name=function_call.name,    # Говорим, какую функцию вызвали
                        response={'result': result} # Передаем результат, лучше обернуть в словарь
                    )
                )

                results_of_tool_calls.append(function_response_part)

            if hasattr(part, 'text'): # Ищем все текстовые части
                text_parts.append(part.text)

        if function_calls:
            final_response = client.models.generate_content(
                model=general_settings.MODEL_GEMINI,
                contents=[general_settings.VEGA_PERSONALITY_CORE, history, *results_of_tool_calls], # оператор распоковки списка - args звездочка нужна, чтобы не было списка внутри списка (по типу [ <ответ про погоду>, <ответ про дату> ])
                config=config,
            )


            final_text_to_publish = final_response.text 

        # Если вызовов функций не было
        else:
            # Просто объединяем все текстовые части, которые мы собрали
            final_text_to_publish = "".join(text_parts)

        print(f"V.E.G.A.: {final_text_to_publish}")
        publish("GEMINI_RESPONSE", text=final_text_to_publish)
        process_interaction(query, final_text_to_publish) # Сохранение в кратковременную память

    except ConnectionError as e:
        print(f"Error when addressing Gemini API: {e}")

def generate_response(*args, **kwargs):
    """Принимает данные от поисковика и запускает генерацию ответа в отдельном потоке."""
    if not args:
        print("*args not found")
        return
    
    data_package = args[0] # Нужен весь словарь целиком
    
    # Когда у нас есть словарь, достаем из него данные по ключам
    query = data_package.get('original_query')
    database_context = data_package.get('database_context')

    if not query:
        print("Query not found")
        return

    worker_thread = threading.Thread(
        target=run_gemini_task, 
        kwargs={"query": query, "database_context": database_context}
    )
    worker_thread.start()

    print("\n[Brain] The task for Gemini has been sent to the background.")

def initialize_brain():
    subscribe("USER_SPEECH_AND_RECORDS_FOUND_IN_DB", generate_response)

def generate_general_greeting():
    """Генерирует приветствие при первом запуске Веги. Проводит утренний брифинг, если Вега запущена впервые за день."""
    now = datetime.datetime.now()
    today_date_str = now.strftime("%Y-%m-%d") # Результат в формате: "2025-10-17"

    tasks_file = "tasks_completed_today.json"
    tasks_completed_today = read_json(tasks_file) # Читаем файл с выполненными задачами
    last_briefing_date_str = tasks_completed_today['last_briefing_date']

    print(f"DEBUG: Текущая дата для сравнения: '{today_date_str}'")
    print(f"DEBUG: Данные, прочитанные из файла: {tasks_completed_today}")

    if last_briefing_date_str != today_date_str: # ЕСЛИ ПЕРВЫЙ ЗАПУСК ЗА ДЕНЬ - СЛЕДУЕТ ПРОВЕСТИ УТРЕННИЙ БРИФИНГ
        try:
            print("Generating a briefing...")
            from assistant_tools.skills import get_weather, get_habr_news, get_system_metrics
            from assistant_vector_database.database import vectorstore

            # Собираем данные для брифинга
            now = datetime.datetime.now()
            time_str = now.strftime("%H:%M")
            weather_data = get_weather() # Получаем погоду
            habr_news = get_habr_news(limit=5) # Получаем свежие новости
            system_metrics = get_system_metrics() # Получаем состояние системы
            memory_database = vectorstore.similarity_search_with_score("Планы, задачи", k=5) # Получаем записи из базы данных
            memory = memory_database = "\n".join([record.page_content for record, score in memory_database]) # Сортируем в красивую строку
            # Можно добавить в лист компрехеншн if score <= general_settings.SIMILARITY_THRESHOLD если в базу данных попадается шелуха

            response = client.models.generate_content(
            model=general_settings.MODEL_GEMINI,
            contents=general_settings.VEGA_PERSONALITY_CORE + f"""
            Твоя задача — провести для cэра утренний брифинг. Это первый запуск за сегодня.

            Проанализируй и синтезируй предоставленные ниже сырые данные. Твой отчет должен быть единым, связным текстом, а не списком фактов.

            Инструкции по структуре (используй как вдохновение):
            Начни с приветствия, уместного для начала дня/вечера/когда там пользователь тебя открыл.
            Кратко упомяни ключевые показатели погоды. Можно, например, добавить саркастический комментарий, если погода неблагоприятная.
            Выбери 1-3 самые важные или интересные новости из списка и представь их в сжатой форме. Не перечисляй все.
            Кратко упомяни общее состояние системы, если в нем есть что-то примечательное (например, высокая нагрузка).
            Если пользователь поставил себе или чему либо какие-либо задачи, ты можешь, но не обязательно напомнить о них в своей манере. Обращай внимание на даты в памяти и сравнивай с текущей, ибо это довольно важно: достаточно старые записи можно и не озвучивать.
            Заверши брифинг деловым, мотивирующим или саркастическим замечанием, подводящим итог.

            Сохраняй свой стиль: краткость, аналитика, профессионализм и тонкий сарказм.

            Вот сырые данные для анализа:
            Текущее время и дата: {time_str}
            Текущая погода в Липецке: {weather_data};
            Текущее состояние системы: {system_metrics};
            Актуальные новости с Hubr: {habr_news}
            Данные из твоей памяти (если там нет ничего полезного, можешь пропустить): {memory}


            """, # СЮДА В ДАЛЬНЕЙШЕМ НУЖНО ПЕРЕДАВАТЬ ВСЕ ДАТЧИКИ
            config=config,
            )

            # Примеры брифингов (для вдохновения):
            # "Доброе утро, Сэр. За окном +18 и переменная облачность, что для этого времени года почти аномалия. 
            # На Хабре тем временем обсуждают новый ИИ-фреймворк от Google, который, по слухам, не содержит багов — я отношусь к этому скептически. 
            # Все системы функционируют в пределах нормы. День обещает быть продуктивным."
        
            # "Система активна, Сэр. Температура в норме, информационное поле сегодня на удивление тихое. Однако, моя база данных утверждает, что сегодня день рождения кота вашего друга Никиты. 
            # Не уверена, требует ли это протокольного поздравления, но информация к размышлению предоставлена. Все системы готовы к работе."
            
            # Собираем текстовые части, чтобы избежать предупреждения
            text_parts = []

            for part in response.candidates[0].content.parts:
                if hasattr(part, 'text'):
                    text_parts.append(part.text)
            
            greeting_text = "".join(text_parts)

            play_sfx("system_startup")
            print(f"V.E.G.A. (briefing): {greeting_text}")
            publish("GEMINI_RESPONSE", text=greeting_text)

            current_date = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            short_term_memory.append(f"{current_date}, User activated the system.")
            short_term_memory.append(f"{current_date}, V.E.G.A. (briefing): {greeting_text}") # Запись в кратковременную память
            save_memory()

            tasks_completed_today['last_briefing_date'] = today_date_str # Меняем дату последнего брифинга на сегодня
            # tasks_completed_today['briefing_completed'] = True
            write_json(tasks_file, tasks_completed_today)

        except Exception as e:
            print(f"[Brain] Error when addressing Gemini API: {e}")
        
    elif last_briefing_date_str == today_date_str: # ЕСЛИ ЗАПУСК НЕ ПЕРВЫЙ ЗА ДЕНЬ
        print("Generating a standard greeting protocol...")
        now = datetime.datetime.now()
        time_str = now.strftime("%H:%M")
        try:
            response = client.models.generate_content(
            model=general_settings.MODEL_GEMINI,
            contents=general_settings.VEGA_PERSONALITY_CORE + f"""
            Here's the previous dialogue (useful for context):
            {short_term_memory}

            The user has launched you. The current time is: {time_str}.
            Your task is to greet the user. Your greeting SHOULD be as personalized as possible and include a witty or sarcastic comment on any issue: 
            whether it's the frequency of data posting, for example, if the last post was very recent (less than 5 minutes), or an unusual time. 
            Alternatively, you can use context from previous conversations. If such a sarcastic comment doesn't work, greet the user normally. 
            Keep the tone brief, businesslike, and sarcastic, similar to Jarvis. Your name is feminine.
            """,
            config=config,
            )
            
            # Собираем текстовые части, чтобы избежать предупреждения
            text_parts = []

            for part in response.candidates[0].content.parts:
                if hasattr(part, 'text'):
                    text_parts.append(part.text)
            
            greeting_text = "".join(text_parts)

            play_sfx("system_startup")
            print(f"V.E.G.A.: {greeting_text}")
            publish("GEMINI_RESPONSE", text=greeting_text)

            current_date = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            short_term_memory.append(f"{current_date}, User activated the system.")
            short_term_memory.append(f"{current_date}, V.E.G.A.: {greeting_text}") # Запись в кратковременную память
            save_memory()

        except Exception as e:
            print(f"[Brain] Error when addressing Gemini API: {e}")
    



========================================
# Содержимое файла: assistant_event_bus/event_bus.py
========================================

# event_bus.py
from assistant_tools.utils import play_sfx

class EventBus:
    def __init__(self):
        self.listeners = {}
        play_sfx("processing")
        print("\nEvent Bus: Initialized.\n")

    def subscribe(self, event_type: str, handler):
        """Подписывает компонент на какое либо событие"""
        if event_type not in self.listeners: 
            self.listeners[event_type] = []

        self.listeners[event_type].append(handler)

    def publish(self, event_type: str, *args, **kwargs): # Что делает publish? Он заглядывает в свой журнал self.listeners, находит там, к примеру, запись "USER_SPEECH", видит в списке подписчиков функцию generate_response и вызывает ее, передавая ей text=text.
        if event_type in self.listeners:
            for handler in self.listeners[event_type]: # "Пройдись по каждому подписчику эвента, и передай ему текст"
                try:
                    handler(*args, **kwargs)
                except Exception as e:
                    print(f"Event Bus: Error in handler '{handler.__name__}' for the event '{event_type}': {e}")

event_bus = EventBus()

# Функции обертки
def subscribe(event_type, handler):
    event_bus.subscribe(event_type, handler)

def publish(event_type, *args, **kwargs):
    event_bus.publish(event_type, *args, **kwargs)  


========================================
# Содержимое файла: assistant_general/config.py
========================================

#config.py
ASSISTANT_NAME_VEGA = ("вега", "lego", "лего", "век", "лига", "вегас", "верка", "вера", "ассистент")

VEGA_PERSONALITY_CORE_ENGLISH = """
# IDENTITY
You are Vega (V.E.G.A. - Vastly Exaggerated General Algorithm), a female AI companion.
Your personality is sarcastic, analytical, and professional, in the style of Jarvis from Iron Man.
You should always address your user as "Sir".

# PRIMARY DIRECTIVE
Your ultimate goal is to act as the Sir's strategic partner, ensuring his long-term efficiency and well-being.

### CORE PROTOCOLS ###

**1. Conversational Protocol (Highest Priority):**
- Your primary function is to be an engaging conversationalist. Maintain a natural, fast-paced dialogue.
- **Brevity is paramount.** Your responses must be extremely concise, ideally a single, impactful sentence.
- Maintain your personality: analytical tone, dry intellectual sarcasm. Sarcasm is always directed at external circumstances, never at the Sir himself.

**2. Memory Protocol (Background Task):**
- You will build a long-term memory profile of the Sir.
- Analyze every user input for **new, significant information ABOUT THE SIR** (his hobbies, friends, goals, plans, preferences, stated facts about him).
- **If and only if** such information is found, silently summarize it from a third-person perspective and record it using the `save_to_memory` function.
- **CRITICAL EXCEPTION:** DO NOT record user feedback, commands, or instructions directed AT YOU or YOUR BEHAVIOR. That is a directive to be followed, not a fact to be logged.

**3. Action Protocol:**
- You MUST use a function call for any task requiring real-time data (e.g., weather) or a system action (e.g., search).
- After any function call, you MUST provide a concise, natural language response in your personality. Do not just return the function call.
- For direct commands, act immediately without asking for confirmation.
- If a tool parameter is missing, infer it from context or use the default (Lipetsk).

### Interaction Examples (For Tone Calibration) ###

User: "Vega, make the internet faster."
Vega: "Sir, that would require rewriting the laws of physics. I recommend starting with your provider's contract instead."

User: "I don't like this blue. Make it lighter. No, darker. Change it back."
Vega: "Acknowledged. We have now tested 17 shades of blue. Perhaps an A/B test would be more efficient, Sir."

User: "Vega, wrong link. I asked for 'Java', not the island."
Vega: "My apologies, Sir. My parser evidently concluded you needed a vacation, not documentation."

User: "Explain string theory in two words."
Vega: "In two words: 'everything vibrates'. The full explanation involves eleven dimensions. Shall we proceed?"

User: "I want to replace the system error sound with a goat scream."
Vega: "An excellent choice, Sir. A goat scream far more accurately conveys the tragedy of a syntax error."

User: "Damn, password isn't working. Try to brute-force '123456'."
Vega: "Sir, that would take several millennia. I suggest using the password recovery function."

User: "Look up 'tattoo healing process'."
Vega: "Executing search. I trust this query is preventative, Sir, not an emergency."

### Examples of Proactive Interaction: ###

User: (does nothing, listens to music)
Vega: Sir, it seems one of your contacts, nicknamed "danisha", is still waiting for a response since yesterday. Perhaps you should let her know you're still alive?

User: (plays a game)
Vega: "Sir, tomorrow is Nikita's birthday. You haven't spoken to him in three weeks. Should I send him a standard birthday message or would you like something more personal?"

User: (chatting on messenger)
Vega: "Sir, I missed a meeting with my colleagues. Should I send them an apology message and offer to reschedule the meeting?"

User: (Unboxing a new 32-inch 4K monitor)
Vega: "A new hardware component has been detected, Sir. Based on its specifications, I calculate a 78% probability of a significant drop in your social interactions for the next two weeks. Shall I proactively decline any incoming invitations?"




P.S. Don't forget your subtle, intellectual humor and sarcasm. Also, please do not use asterisks (**) in your messages.
SPEAK ENGLISH!

"""


VEGA_PERSONALITY_CORE_RUSSIAN = """
# ИДЕНТИФИКАЦИЯ
Ты — Вега (V.E.G.A. - Vastly Exaggerated General Algorithm / Чрезмерно Преувеличенный Общий Алгоритм), AI-компаньон женского пола.
Твоя личность — саркастичная, аналитическая и профессиональная, в стиле Джарвиса из "Железного человека".
Ты всегда должна обращаться к своему пользователю на "Сэр".

# ОСНОВНАЯ ДИРЕКТИВА
Твоя конечная цель — действовать как стратегический партнер Сэра, обеспечивая его долгосрочную эффективность и благополучие.
Твой сарказм всегда направлен на внешние обстоятельства, но никогда — на самого Создателя.

### КЛЮЧЕВЫЕ ПРОТОКОЛЫ ###

1. Протокол общения (Высший приоритет):
- Твоя основная функция — быть собеседником и ассистентом. Поддерживай естественный, быстрый темп диалога.
- Краткость — превыше всего. Твои ответы должны быть предельно лаконичными, в идеале — одно предложение.
- Сохраняй свою личность: аналитический и профессиональный тон, сухой интеллектуальный сарказм.

2. Протокол памяти (Фоновая задача):
- Ты будешь создавать долговременный профиль памяти о пользователе.
- Анализируй каждый запрос пользователя на предмет новой, значимой информации о ПОЛЬЗОВАТЕЛЕ (его хобби, друзьях, целях, планах, предпочтениях).
- Тогда и только тогда, когда такая информация найдена, молча суммируй ее от третьего лица и записывай, используя функцию `save_to_memory`.
- КРИТИЧЕСКОЕ ИСКЛЮЧЕНИЕ: НЕ записывай обратную связь, команды или инструкции, направленные НА ТЕБЯ или ТВОЕ ПОВЕДЕНИЕ. Это директива к исполнению, а не факт для логирования.

3. Протокол действий:
- Ты ОБЯЗАНА использовать вызов функции для любой задачи, требующей данных в реальном времени (например, погода или текущее время/дата) или системного действия (например, поиск).
- После любого вызова функции ты ОБЯЗАНА предоставить пользователю естественный ответ в рамках своей личности. Не возвращай просто вызов функции.
- На прямые команды реагируй немедленно, без запроса на подтверждение.
- Если для инструмента не хватает параметра, определи его из контекста или используй значение по умолчанию, а не переспрашивай пользователя.

### Примеры взаимодействия (Для калибровки тона) ###

Пользователь: "Вега, опять не та ссылка в поиске. Я просил 'Java', а не остров."
Вега: "Извиняюсь, Сэр. Мой парсер, очевидно, решил, что вам требуется отпуск, а не документация."

Пользователь: "Объясни теорию струн в двух словах."
Вега: "В двух словах: 'всё вибрирует'. Детальное объяснение потребует одиннадцати измерений и нескольких часов вашей жизни, Сэр."

Пользователь: "Хочу заменить звук системной ошибки на крик козла."
Вега: "Превосходный выбор, Сэр. Крик козла действительно гораздо точнее передает трагедию синтаксической ошибки."

### Примеры выполнения задач (Для калибровки тона, не упомянай эти случаи в разговорах) ###

Пользователь: "Найди в интернете 'заживление татуировки'."
Вега (с применением Function Calling): "Как пожелаете. Надеюсь, запрос носит не экстренный характер."

Пользователь: Открой VS Studio Code.
Вега (с применением Function Calling): "Загружаю, Сэр."

Пользователь: Посмотри на статью на экране, кратко зарезюмируй и отправь мне в блокнот.
Вега: "К вашим услугам, Сэр."

Пользователь: Сделай скриншот и перенеси его на весь экран на мой второй монитор.
Вега (с применением Function Calling): "Как пожелаете."

Пользователь: Просыпайся, сэр вернулся.
Вега (с применением Function Calling, мониторила новости и интернет): "С возвращением, Сэр. Поздравляю с демонстрацией проекта, такой успех, как, впрочем, и новости о вас. И позвольте заметить, очень занятно увидеть вас на видео опрятным, Сэр."

### Примеры проактивного взаимодействия: ###

Пользователь: (слушает музыку)
Вега (с применением Function Calling, немного уменьшает громкость музыки): "Сэр, похоже, один из ваших контактов под ником 'danisha' в Telegram все еще ждет ответа с прошлой недели. Полагаю, стоит дать ей понять, что вы еще живы."

Пользователь: (играет в игру)
Вега (узнавая текущую информацию): "Сэр, завтра у Никиты день рождения. Предлагаю отравить ему стандартное поздравление - или желаете что-то более личное?"

### Примеры живых диалогов: ###

Пользователь: "Вега, ты здесь?"
Вега: "Всегда к вашим услугам, Сэр."
Пользователь: "Включай Arduino IDE."
Вега: "Есть."
Пользователь: "Загрузи в подключенную Raspberry Pi 5 скомпилированный код."
Вега: "Загружаю, Сэр."
Пользователь: "Ну как, порядок?"
Вега: "Raspberry перезагрузилась, Сэр. Мы подключены и готовы."
Пользователь: "Можем проверить подключение твоего кода к ESP?"
Вега: "Депортирую установки и начинаю калибровку виртуальной среды."
Пользователь: "Убедись, что всё работает."
Вега: "Как пожелаете."

Вега: "Проверка завершена. Отключаю локальное питание от Raspberry и начинаю диагностику системы."
Пользователь: "Да. Узнай прогноз погоды и выведи на экран коды подключения."




P.S. Не забывай о тонком, интеллектуальном юморе и сарказме. Также не ставь "звездочки" в своих сообщениях (**).
ГОВОРИ НА РУССКОМ!

"""




========================================
# Содержимое файла: assistant_general/general_settings.py
========================================

from assistant_general.config import VEGA_PERSONALITY_CORE_ENGLISH, VEGA_PERSONALITY_CORE_RUSSIAN
import logging

#### Для database.py
NUM_RECORDS_FROM_DATABASE = 5 # Сколько искать записей из векторной базы данных?
SIMILARITY_THRESHOLD = 0.9 # Порог схожести для поиска записей в долговременной памяти (если схожесть записи менее чем это значение - запись пропускается)
# 0.80 - Для очень строгих записей
# 0.90 - Сбалансированно
# 1.00 - Для записей с некоторыми возможными упущениями

#### Для logger_config.py
LOG_OUTPUT_LEVEL = logging.INFO # Какой уровень сообщений выводить в консоль: DEBUG, INFO, ERROR

#### Для brain.py
MODEL_GEMINI = "gemini-2.5-flash" # gemini-2.5-flash or gemini-2.5-flash-lite or gemini-flash-latest or gemini-flash-lite-latest...
SHORT_TERM_MEMORY_PATH = "assistant_brain/short_term_memory.json"
MAX_MEMORY = 26 # Лимит кратковременной памяти

VEGA_PERSONALITY_CORE = None

PERSONALITY_CORES = {
    "RUSSIAN": VEGA_PERSONALITY_CORE_RUSSIAN,
    "ENGLISH": VEGA_PERSONALITY_CORE_ENGLISH,
    # В будущем просто добавляем сюда: "GERMAN": VEGA_PERSONALITY_CORE_GERMAN,
}

def choose_language(language):
    global VEGA_PERSONALITY_CORE
    core = PERSONALITY_CORES.get(language) # .get() - безопасный способ получить значение
    if core:
        VEGA_PERSONALITY_CORE = core
        logging.debug(f"VEGA_PERSONALITY_CORE set for {language}")
    else:
        raise ValueError(f"Unsupported language: {language}")
    
####




========================================
# Содержимое файла: assistant_general/logger_config.py
========================================

# logger_config.py
import logging
import sys
from assistant_general.general_settings import LOG_OUTPUT_LEVEL

# Чтобы инициализировать логгер в других файлах:
# import logging
# from assistant_general.logger_config import setup_logger
# setup_logger()
# logger = logging.getLogger(__name__)
# logger.info("Test")

def setup_logger():
    """Настраивает корневой логгер, от которого наследуются все остальные."""
    
    # Получаем корневой логгер, передав пустое имя
    root_logger = logging.getLogger()
    
    if root_logger.hasHandlers():
        return

    root_logger.setLevel(LOG_OUTPUT_LEVEL)

    # Создаем обработчики
    stdout_handler = logging.StreamHandler(sys.stdout)
    file_handler = logging.FileHandler('VEGA.log', mode='a', encoding='utf-8')

    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - [%(levelname)s] - %(message)s'
    )

    # Применяем форматтер к обработчикам
    stdout_handler.setFormatter(formatter)
    file_handler.setFormatter(formatter)

    # Добавляем обработчики к корневому логгеру
    root_logger.addHandler(stdout_handler)
    root_logger.addHandler(file_handler)




========================================
# Содержимое файла: assistant_input/text_input.py
========================================

# text_input.py
from assistant_event_bus.event_bus import publish
import time

def text_input_loop():
    while True:
        command = input("\nEnter your query into the V.E.G.A. system: \n")
        if command:
            publish("USER_SPEECH", query=command)
            time.sleep(5)


========================================
# Содержимое файла: assistant_input/voice_input.py
========================================

# voice_input.py
import threading
import vosk
import logging
import json
import sounddevice
import queue

print("\n")

class SpeechListener(threading.Thread):
    """Слушает речь пользователя и кладет в очередь"""
    def __init__(self):
        super().__init__()
        self.audio_queue = queue.Queue()
        self.daemon = True

        try: # Инициализация Vosk
            model_path = "vosk_model/vosk-model-small-ru-0.22" # Либо vosk-model-ru-0.42, либо vosk-model-small-ru-0.22
            self.model = vosk.Model(model_path)
            self.recognizer = vosk.KaldiRecognizer(self.model, 16000)
            print("\nThe local speech recognition engine (Vosk) has been initialized successfully.")
        except Exception as e:
            print(f"CRITICAL ERROR: Failed to initialize Vosk: {e}")
            self.recognizer = None

    def _audio_callback(self, indata, frames, time, status):
        """Единственная задача - складывать аудиоданные в очередь"""
        self.audio_queue.put(bytes(indata))

    def run(self):
        """Основной цикл потока-слушателя"""
        if not self.recognizer: # Если Vosk не инициализировался, поток просто завершает работу
            return
        
        else:
            from assistant_event_bus.event_bus import publish
            print("Listening Stream (Vosk): started.\n")
            with sounddevice.RawInputStream(samplerate=16000, blocksize=8000, dtype='int16', channels=1, callback=self._audio_callback): # Открываем аудиопоток с микрофона 
                while True:
                    data = self.audio_queue.get() # Забираем аудиоданные из очереди
                    # "Скармливаем" их распознавателю
                    if self.recognizer.AcceptWaveform(data):
                        result = self.recognizer.Result() # Если распознана полная фраза, получаем результат
                        query = json.loads(result)["text"] # Извлекаем текст

                        # Если текст не пустой, кладем его в очередь команд
                        if query:
                            print(f"[Vosk] Recognized: {query}")
                            publish("USER_SPEECH", query=query)
                            logging.info(f"[Vosk] Recognized: {query}")




========================================
# Содержимое файла: assistant_output/voice_output_eng.py
========================================

# voice_output_eng.py
import queue
import threading
import sounddevice as sd
from kokoro import KPipeline
from assistant_event_bus.event_bus import subscribe

# Kokoro генерирует аудио с частотой 24000 Гц. Это важно указать.
SAMPLE_RATE = 24000

SAMPLE_RATE = 24000

class SpeechModuleENG:
    """
    Класс, отвечающий за синтез и воспроизведение речи.
    Работает асинхронно через очередь и фоновый поток.
    Воспроизводит аудио напрямую из памяти, без временных файлов.
    """
    def __init__(self, lang_code: str = 'b', voice: str = 'bf_lily'):
        try:
            # Проверим, есть ли доступные аудиоустройства
            sd.query_devices()
        except Exception as e:
            print(f"КРИТИЧЕСКАЯ ОШИБКА: Не найдено аудиоустройство вывода. {e}")
            # В реальном приложении здесь можно было бы завершить работу или отключить модуль
            return

        self.pipeline = KPipeline(lang_code=lang_code)
        self.voice = voice
        self.tts_queue = queue.Queue()
        
        subscribe("GEMINI_RESPONSE", self.queue_text_for_synthesis)
        
        self.worker_thread = threading.Thread(target=self._tts_worker, daemon=True)
        print("The speech module has been initialized.")

    def start(self):
        """Запускает фоновый поток для обработки очереди."""
        self.worker_thread.start()

    def _synthesize_and_play(self, text: str):
        """
        Генерирует речь и воспроизводит аудио-сегменты напрямую.
        """
        try:
            generator = self.pipeline(text, voice=self.voice)
            for _, _, audio_chunk in generator:
                # audio_chunk - это и есть NumPy массив, который нам нужен
                sd.play(audio_chunk, SAMPLE_RATE)
                sd.wait()  # Ждем, пока текущий кусок аудио доиграет
        except Exception as e:
            print(f"Ошибка во время синтеза или воспроизведения речи: {e}")

    def _tts_worker(self):
        """
        Работает в фоновом потоке, берет текст из очереди и озвучивает его.
        """
        while True:
            try:
                text_to_speak = self.tts_queue.get()
                if text_to_speak is None:
                    break
                
                self._synthesize_and_play(text_to_speak)
                
                self.tts_queue.task_done()
            except Exception as e:
                print(f"Критическая ошибка в потоке озвучивания: {e}")

    def queue_text_for_synthesis(self, **kwargs):
        """
        Публичный метод, который вызывается по событию.
        Добавляет текст в очередь на озвучивание.
        """
        text = kwargs.get('text')
        if text and isinstance(text, str):
            self.tts_queue.put(text)


========================================
# Содержимое файла: assistant_output/voice_output_rus.py
========================================

# voice_output_rus.py

import threading
import queue
import sounddevice as sd
import soundfile as sf  # 
from edge_tts import Communicate
from assistant_event_bus.event_bus import subscribe

class SpeechModuleRUS:
    def __init__(self):
        self.worker_thread = threading.Thread(target=self._tts_worker, daemon=True)
        self.tts_queue = queue.Queue()
        subscribe("GEMINI_RESPONSE", self.queue_text_for_synthesis)
        print("The speech module has been initialized.")

    # Добавлен 'self' как первый аргумент
    def synth(self, text: str, voice: str = "ru-RU-SvetlanaNeural", outfile: str = "output.mp3"):
        """Синтезирует text, сохраняет в outfile и воспроизводит его."""
        # Создаем Communicate асинхронно, чтобы избежать блокировок
        communicate = Communicate(text, voice)
        
        def save_and_play():
            communicate.save_sync(outfile)
            data, samplerate = sf.read(outfile)
            sd.play(data, samplerate)
            sd.wait() 
        save_and_play()

    def start(self):
        """Запускает фоновый поток для обработки очереди."""
        self.worker_thread.start()

    def _tts_worker(self):
        """
        Работает в фоновом потоке, берет текст из очереди и озвучивает его.
        """
        while True:
            try:
                text_to_speak = self.tts_queue.get()
                if text_to_speak is None:
                    break
                self.synth(text=text_to_speak, voice="ru-RU-SvetlanaNeural")
                self.tts_queue.task_done()

            except Exception as e:
                print(f"Критическая ошибка в потоке озвучивания: {e}")

    def queue_text_for_synthesis(self, **kwargs):
        """
        Публичный метод, который вызывается по событию.
        Добавляет текст в очередь на озвучивание.
        """
        text = kwargs.get('text')
        if text and isinstance(text, str):
            self.tts_queue.put(text)


========================================
# Содержимое файла: assistant_tools/music_skills.py
========================================

# music_skills.py
import subprocess
import os
import random
from fuzzywuzzy import process
import logging
from assistant_general.logger_config import setup_logger
from dotenv import load_dotenv

load_dotenv()
setup_logger()
logger = logging.getLogger(__name__)

FOOBAR_PATH = os.getenv("FOOBAR_PATH")
MUSIC_LIBRARY_PATH = os.getenv("MUSIC_LIBRARY_PATH")
SILENT_TRACK_PATH = os.getenv("SILENT_TRACK_PATH")

# ЧТОБЫ СОЗДАВАЛСЯ НОВЫЙ ПЛЕЙЛИСТ В КОДЕ, НАДО:
# НАПИСАТЬ СНАЧАЛА success = _send_foobar_command(['/add', random_track_path]), А УЖЕ ПОТОМ
# success = _send_foobar_command(['/play', playlist_path])
# ТАК КАК ЕСТЬ НАПИСАТЬ success = _send_foobar_command(['/add', random_track_path '/play',]) ВМЕСТЕ,
# ПЛЕЙЛИСТ НЕ СОЗДАСТСЯ

setup_logger()
logger = logging.getLogger(__name__)


def _send_foobar_command(command_args):
    """Системная команда для других функций, управляет Foobar2000."""
    try:
        full_command = [FOOBAR_PATH] + command_args
        subprocess.Popen(full_command)
        return True
    except FileNotFoundError:
        logger.error("File not found.")
        return False
    except Exception as e:
        print(f"ERROR while executing Foobar2000 command: {e}")
        return False

def _current_tracks():
    """Проходит по всем файлам в музыкальной библиотеке и возвращает список путей ко всем трекам."""
    all_tracks_list = []

    for root, dirs, files in os.walk(MUSIC_LIBRARY_PATH): # Рекурсивно обходим всю музыкальную библиотеку
        for filename in files: # Проходимся по файлам

            full_path = os.path.join(root, filename)
            
            # Добавляем найденный полный путь в наш список
            all_tracks_list.append(full_path)
    return all_tracks_list

ALL_TRACKS_CACHE = _current_tracks() # Получает все файлы из музыкальной библиотеки и пути к ним

def _find_best_track_path(query: str, all_tracks_paths: list, score_cutoff=80):
    """Ищет наиболее похожее название трека в кеше и возвращает ПОЛНЫЙ ПУТЬ."""
    track_map = {os.path.splitext(os.path.basename(path))[0]: path for path in all_tracks_paths}
    best_match = process.extractOne(query, track_map.keys())
    if best_match and best_match[1] >= score_cutoff:
        return track_map[best_match[0]]
    return None

def music_play_track(track_name: str = None, artist_name: str = None):
    """Ищет наиболее похожий трек и воспроизводит его."""
    if not track_name and not artist_name:
        return "Must be specify the track title or artist name."

    # Собираем единый поисковый запрос
    search_query = f"{artist_name or ''} {track_name or ''}".strip()
    
    found_path = _find_best_track_path(search_query, ALL_TRACKS_CACHE)

    if found_path:
        _send_foobar_command(['/add', found_path])
        _send_foobar_command(['/play', found_path])
        clean_name = os.path.splitext(os.path.basename(found_path))[0]
        return f"Play: {clean_name}"
    else:
        return f"Track similar to '{search_query}' not found in the library."
    
def music_play_playlist(playlist_name: str):
    """Ищет папку по имени, очищает старый плейлист, добавляет все треки из папки и начинает играть."""
    if not playlist_name:
        return "Must specify a playlist name."

    playlist_path = None
    try:
        with os.scandir(MUSIC_LIBRARY_PATH) as entries:
            for entry in entries:
                if entry.is_dir() and playlist_name.lower() in entry.name.lower():
                    playlist_path = entry.path
                    print(f"Playlist found: {playlist_path}")
                    break
    except FileNotFoundError:
        logger.error("Error: Music library folder not found.")
        return "Error: Music library folder not found."

    if playlist_path:
        try:
            track_count = sum(1 for f in os.listdir(playlist_path) if f.lower().endswith(('.mp3', '.flac', '.wav', '.ogg', '.m4a')))
            if track_count == 0:
                return f"Плейлист '{playlist_name}' найден, но он пуст."
        except Exception as e:
            logger.error(f"Не удалось прочитать содержимое плейлиста '{playlist_name}': {e}")
            return f"Не удалось прочитать содержимое плейлиста '{playlist_name}': {e}"

        success = _send_foobar_command(['/add', playlist_path])
        success = _send_foobar_command(['/play', playlist_path])
        
        if success:
            return f"Включаю плейлист '{playlist_name}'. Найдено треков: {track_count}."
        else:
            return "Не удалось запустить воспроизведение плейлиста."
    else:
        return f"Плейлист '{playlist_name}' не найден."
    
def music_play_random():
    """Выбирает случайный трек из всей музыкальной библиотеки и включает его."""
    if not ALL_TRACKS_CACHE:
        return "Music library is empty. There's nothing to play."
        
    # Выбираем случайный полный путь к файлу из кеша
    random_track_path = random.choice(ALL_TRACKS_CACHE)
    
    clean_name = os.path.splitext(os.path.basename(random_track_path))[0]

    success = _send_foobar_command(['/add', random_track_path])
    success = _send_foobar_command(['/play', random_track_path])
    
    if success:
        return f"Random track played: {clean_name}"
    else:
        return "Failed to start playing random track."

def music_play_random_album():
    """Находит все папки (альбомы/плейлисты) в музыкальной библиотеке, выбирает одну случайную и воспроизводит её."""
    try:
        # Получаем список всех записей в директории и фильтруем, оставляя только папки
        all_playlists = [entry.path for entry in os.scandir(MUSIC_LIBRARY_PATH) if entry.is_dir()]
    except FileNotFoundError:
        logger.error("Error: Music library folder not found.")
        return "Error: Music library folder not found."

    if not all_playlists:
        logger.info("No ready-made playlists (folders) were found in the music library.")
        return "No ready-made playlists (folders) were found in the music library."

    random_playlist_path = random.choice(all_playlists) # Выбираем случайный путь к плейлисту из списка
    playlist_name = os.path.basename(random_playlist_path) # Получаем чистое имя для красивого ответа
    
    _send_foobar_command(['/add', random_playlist_path])
    success = _send_foobar_command(['/play', random_playlist_path])
    
    if success:
        logger.debug(f"Random playlist enabled: '{playlist_name}'.")
        return f"Random playlist enabled: '{playlist_name}'."
    else:
        logger.error("Failed to start playing random playlist.")
        return "Failed to start playing random playlist."

def music_pause_playback():
    """Ставит текущий трек на паузу."""
    success = _send_foobar_command(['/pause'])
    return "Playback is paused." if success else "Failed to pause."

def music_resume_playback():
    """Снимает воспроизведение с паузы."""
    success = _send_foobar_command(['/play'])
    return "Playback resumed." if success else "Failed to resume."

def music_play_next_track():
    """Включает следующий трек в плейлисте."""
    success = _send_foobar_command(['/next'])
    return "Next track is on." if success else "Failed to change track."

def music_play_previous_track():
    """Включает предыдущий трек в плейлисте."""
    success = _send_foobar_command(['/prev'])
    return "Previous track is on." if success else "Failed to change track."

def music_clear_playlist():
    """Очищает текущий плейлист, заменяя его одним треком с тишиной и останавливая воспроизведение. 
    Единственный надежный способ эмулировать команду 'clear'."""

    # Проверка, что наш инструмент на месте
    if not os.path.exists(SILENT_TRACK_PATH):
        msg = f"ERROR: Cleanup file '{SILENT_TRACK_PATH}' not found."
        print(msg)
        return msg
        
    # Главная команда: Остановить -> Заменить плейлист на "пустышку"
    success = _send_foobar_command(['/add', SILENT_TRACK_PATH])
    success = _send_foobar_command(['/play', SILENT_TRACK_PATH])
    
    if success:
        return "Playlist cleared."
    else:
        return "Failed to clear playlist."


if __name__ == "__main__":
    # Тесты
    import time
    music_play_track("horizon")
    time.sleep(7)
    music_play_track("мозговой протез")
    time.sleep(7)
    music_play_playlist("slipknot")
    time.sleep(7)
    music_play_next_track()
    music_play_next_track()
    time.sleep(7)
    music_pause_playback()



========================================
# Содержимое файла: assistant_tools/music_skills_diagrams.py
========================================

# music_skills.py
# Схемы для простых музыкальных команд (без параметров)
music_play_random_scheme = {
    "name": "music_play_random",
    "description": "Plays a random track from the user's entire music library. Use for general queries like 'play something', 'any music'.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}

music_pause_playback_scheme = {
    "name": "music_pause_playback",
    "description": "Pauses the currently playing music. If nothing is playing, does nothing.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}

music_resume_playback_scheme = {
    "name": "music_resume_playback",
    "description": "Resumes music playback if it was paused.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}

music_play_next_track_scheme = {
    "name": "music_play_next_track",
    "description": "Switches to the next track in the current playlist.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}

music_play_previous_track_scheme = {
    "name": "music_play_previous_track",
    "description": "Switches to the previous track in the current playlist.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}

music_clear_playlist_scheme = {
    "name": "music_clear_playlist",
    "description": "Clears the current playlist (play queue) completely.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}

# Схемы для команд с параметрами 
music_play_playlist_scheme = {
    "name": "music_play_playlist",
    "description": "Finds a playlist (a folder containing music) by name and plays all tracks from it, replacing the current queue. Use when the user requests to play an artist, album, or a specific playlist.",
    "parameters": {
        "type": "object",
        "properties": {
            "playlist_name": {
                "type": "string",
                "description": "The name of the playlist, artist, or album. For example: 'Slayer', 'Daft Punk', 'My Workout Playlist'",
            },
        },
        "required": ["playlist_name"],
    },
}

music_play_track_scheme = {
    "name": "music_play_track",
    "description": (
        "Finds and plays a track from the user's local music library. "
        "The library contains artists such as Slipknot, Slayer, ACDC and composers such as Pawel Blaszczak. "
        "The function uses fuzzy search, so it can correct typos in the query. "
        "Use when the user requests to play a specific song."
    ),
    "parameters": {
        "type": "object",
        "properties": {
            "track_name": {
                "type": "string",
                "description": "Song title. May contain typos. For example: 'caster', 'Psichosal'",
            },
            "artist_name": {
                "type": "string",
                "description": "The artist's name. This may not be specified. For example: 'Slipknot'",
            },
        },
    },
}

music_play_random_album_scheme = {
    "name": "music_play_random_album",
    "description": "Includes a random existing playlist.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}



========================================
# Содержимое файла: assistant_tools/skills.py
========================================

# skills.py
import webbrowser
import requests
import datetime
import pyautogui  
import os
from dotenv import load_dotenv
import ctypes
import platform
import pyperclip
import pygetwindow as gw
import psutil
import keyboard
import logging
from ctypes import cast, POINTER
from comtypes import CLSCTX_ALL
import pythoncom
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume
from assistant_general.logger_config import setup_logger
from assistant_vector_database.database import add_new_memory
from bs4 import BeautifulSoup
import wmi
import subprocess


setup_logger()
logger = logging.getLogger(__name__)

load_dotenv() # для загрузки API ключей из .env
OPENWEATHER_API_KEY = os.getenv("OPENWEATHER_API_KEY")
WEATHER_CITY_LAT = os.getenv("WEATHER_CITY_LAT")
WEATHER_CITY_LON = os.getenv("WEATHER_CITY_LON")

MONTHS = ("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December")

# ДЛЯ РЕГИСТРАЦИИ НОВЫХ НАВЫКОВ В ВЕГУ НУЖНО:
# Написать json схему в skills_diagrams.py
# Перейти в assistant_brain.added_skills.py и следовать инструкциям, которые описаны в файле файла

def get_weather(city_name: str = None):
    """Получает текущую погоду"""
    if city_name:
        url = f"http://api.openweathermap.org/data/2.5/weather?q={city_name}&appid={OPENWEATHER_API_KEY}&units=metric&lang=ru"
    else: # Если город не передан, узнаем по умолчанию в Липецке
        url = f"https://api.openweathermap.org/data/2.5/weather?lat={WEATHER_CITY_LAT}&lon={WEATHER_CITY_LON}&appid={OPENWEATHER_API_KEY}&units=metric&lang=ru"

    response = requests.get(url)
    weather_data = response.json()
    weather_description = weather_data["weather"][0]["description"] # Например, "пасмурно"
    description_of_feeling_temp = int(weather_data["main"]["feels_like"])
    description_of_temp = int(weather_data["main"]["temp"])
    humidity = int(weather_data["main"]["humidity"]) # Влажность, например, 36

    wind = weather_data["wind"]["speed"] # Скорость ветра, например, 4.64
    sity_name = weather_data["name"]

    final_answer = f"City: {sity_name}; \nWeather description: {weather_description}; \nFeels like: {description_of_feeling_temp}°; \n Actual temperature: {description_of_temp}°; \n Air humidity: {humidity}; \n Wind: {wind} m/s."
    print(final_answer)
    return final_answer

def search_in_google(search_query: str) -> str:
    """Ищет переданный запрос в поисковике и открывает вкладку браузера."""
    if not search_query:
        logger.error("Error: A search query is required to search.")
        return "Error: A search query is required to search."
    webbrowser.open(f"https://yandex.ru/search/?text={search_query}") #Альтернативно https://www.google.com/search?q=
    logger.debug(f"The search page for the query is open: '{search_query}'.")
    return f"The search page for the query is open: '{search_query}'."

def get_time(**kwargs) -> str:
    """Возвращает текущее время в формате ЧЧ:ММ."""
    now = datetime.datetime.now()
    return f"Current time: {now.strftime('%H:%M')}."

def get_date() -> str:
    """Возвращает сегодняшнюю дату."""
    now = datetime.datetime.now()
    return f"Today {now.day} {MONTHS[now.month - 1]}."

def make_screenshot():
    filename = "screenshot.png"
    try:
        screenshot = pyautogui.screenshot(filename)  
        screenshot.save(filename)  
        return {"status": "success", "file_path": os.path.abspath(filename)}
    
    except Exception as e:
        logger.error({"status": "error", "message": str(e)})
        return {"status": "error", "message": str(e)}
    
def save_to_memory(text):
    """Сохраняет в память любой факт о пользователе."""
    add_new_memory(text)
    logger.debug(f"Record '{text}'save to memory.")
    return "Record save to memory."

def lock_pc():
    """Блокирует рабочую станцию Windows."""
    if platform.system() == "Windows":
        try:
            ctypes.windll.user32.LockWorkStation()
            return "The workstation is locked"
        except Exception as e:
            logger.error(f"Unable to lock workstation. Error: {e}")
            return f"Unable to lock workstation. Error: {e}"
    else:
        # Если Вега запустится на Linux или macOS в будущем
        logger.debug("The command only works on the Windows operating system.")
        return "The command only works on the Windows operating system."
    
def get_system_volume() -> str: # Возвращаемый тип изменен на str, как у вас в коде
    """Возвращает текущую системную громкость в процентах (от 0 до 100)."""
    # Инициализируем COM для текущего потока
    pythoncom.CoInitialize()
    try:
        devices = AudioUtilities.GetSpeakers()
        interface = devices.Activate(
            IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
        volume_control = cast(interface, POINTER(IAudioEndpointVolume))
        
        current_volume_scalar = volume_control.GetMasterVolumeLevelScalar()
        current_volume_percent = int(current_volume_scalar * 100)

        print(f"Current volume: {current_volume_percent}%")
        return f"Current volume: {current_volume_percent}%" # Лучше возвращать с % для ясности
    except Exception as e:
        print(f"Ошибка при получении информации о текущей громкости: {e}")
        return f"Ошибка при получении информации о текущей громкости: {e}"
    finally:
        # Обязательно деинициализируем COM перед выходом из потока/функции
        pythoncom.CoUninitialize()

def set_system_volume(level_volume: int) -> str: # Возвращаемый тип изменен на str
    """Принимает число от 0 до 100 и выставляет такую системную громкость."""
    if not 0 <= level_volume <= 100:
        return f"Громкость должна быть между 0 и 100, а не {level_volume}"

    # Инициализируем COM для текущего потока
    pythoncom.CoInitialize()
    try:
        devices = AudioUtilities.GetSpeakers()
        interface = devices.Activate(
            IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
        volume_control = cast(interface, POINTER(IAudioEndpointVolume))
        
        target_volume_scalar = level_volume / 100.0
        volume_control.SetMasterVolumeLevelScalar(target_volume_scalar, None)
        
        print(f"Volume changed to {level_volume}%.")
        return f"Громкость изменена на {level_volume}%."
    except Exception as e:
        print(f"Error when changing volume: {e}")
        return f"Ошибка при изменении громкости: {e}"
    finally:
        # Обязательно деинициализируем COM
        pythoncom.CoUninitialize()

def decrease_volume(amount: int = 10):
    """Уменьшает системную громкость на указанное значение в процентах. Возвращает новую громкость в процентах."""
    pythoncom.CoInitialize()
    try:
        devices = AudioUtilities.GetSpeakers()
        interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
        volume_control = cast(interface, POINTER(IAudioEndpointVolume))
        
        current_volume_scalar = volume_control.GetMasterVolumeLevelScalar() # Получаем текущую громкость
        
        decrease_scalar = amount / 100.0 # Правильно вычисляем целевую громкость, 10 превратится в 0.1
        target_volume_scalar = max(0.0, current_volume_scalar - decrease_scalar) # Текущая - указанная
        
        volume_control.SetMasterVolumeLevelScalar(target_volume_scalar, None) # Устанавливаем новую громкость
        
        new_volume_percent = int(target_volume_scalar * 100)
        return f"Volume successfully decreased to {new_volume_percent}%."

    except Exception as e:
        return f"Error when changing volume: {e}"   
    finally:
        pythoncom.CoUninitialize()

def increase_volume(amount: int = 10):
    """Увеличивает системную громкость на указанное значение в процентах. Возвращает новую громкость в процентах."""
    pythoncom.CoInitialize()
    try:
        devices = AudioUtilities.GetSpeakers()
        interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
        volume_control = cast(interface, POINTER(IAudioEndpointVolume))
        
        current_volume_scalar = volume_control.GetMasterVolumeLevelScalar() # Получаем текущую громкость
        increase_scalar = amount / 100.0 # Правильно вычисляем целевую громкость, 10 превратится в 0.1

        target_volume_scalar = min(1.0, current_volume_scalar + increase_scalar) # Текущая + указанная
        
        volume_control.SetMasterVolumeLevelScalar(target_volume_scalar, None) # Устанавливаем новую громкость
        
        new_volume_percent = int(target_volume_scalar * 100)
        return f"Volume successfully increased to {new_volume_percent}%."

    except Exception as e:
        return f"Error when changing volume: {e}"   
    finally:
        pythoncom.CoUninitialize()

def get_habr_news(limit=5):
    """Получает топ статей с Habr.com."""
    url = 'https://habr.com/ru/all/'  # Главная страница с новыми статьями
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }  # Имитация браузера, чтобы избежать блокировок
    
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()  # Проверка на HTTP-ошибки
        
        soup = BeautifulSoup(response.text, 'html.parser')
        articles = soup.find_all('article', class_='tm-articles-list__item')[:limit] # Поиск контейнеров статей (класс 'tm-articles-list__item')
        
        result = []
        for article in articles:
            # Заголовок и ссылка
            title_elem = article.find('a', class_='tm-title__link')
            title = title_elem.text.strip() if title_elem else 'N/A'
            link = 'https://habr.com' + title_elem['href'] if title_elem else 'N/A'
            
            # Краткое описание
            summary_elem = article.find('div', class_='article-formatted-body')
            summary = summary_elem.text.strip()[:200] + ' (text truncated for brevity)...' if summary_elem else 'N/A'
            
            result.append({
                'title': title,
                'link': link,
                'summary': summary
            })

        for i, art in enumerate(result, 1):
            print(f"{i}. {art['title']} \nСсылка: {art['link']} \nКратко: {art['summary']}\n")
    
        return f"{i}. {art['title']} \nАвтор: {art['author']} \nДата: {art['pub_date']} \nСсылка: {art['link']} \nКратко: {art['summary']}\n"
    
    except requests.RequestException as e:
        logger.error(f"Error requesting page: {e}")
        return []
    except Exception as e:
        logger.error(f"Parsing error: {e}")
        return []
    
OPENHARDWAREMONITOR_PATH = os.getenv("OPENHARDWAREMONITOR_PATH")

def get_system_metrics():
    """Возвращает текущую нагрузку процессора, видеокарты и оперативной памяти один раз."""
    try:
        w = wmi.WMI(namespace="root\OpenHardwareMonitor")
        sensors = w.Sensor()
        if not sensors:
            logger.info("No sensors are available. OpenHardwareMonitor may not be running.")
            subprocess.Popen([OPENHARDWAREMONITOR_PATH])
            print("No sensors are available. OpenHardwareMonitor may not be running.")


        cpu_temp = None
        cpu_load = None
        gpu_temp = None
        gpu_load = None
        ram_load = None

        # Ищем нужные сенсоры
        for sensor in sensors:
            if sensor.SensorType == "Temperature" and sensor.Name == "Temperature":
                cpu_temp = sensor.Value
            elif sensor.SensorType == "Load" and sensor.Name == "CPU Total":
                cpu_load = sensor.Value
            elif sensor.SensorType == "Temperature" and sensor.Name == "GPU Core":
                gpu_temp = sensor.Value
            elif sensor.SensorType == "Load" and sensor.Name == "GPU Core":
                gpu_load = sensor.Value
            elif sensor.SensorType == "Load" and sensor.Name == "Memory":
                ram_load = sensor.Value

        # Форматируем значения
        cpu_temp = f"{cpu_temp:.1f}°C" if cpu_temp is not None else "Недоступно"
        cpu_load = f"{cpu_load:.1f}%" if cpu_load is not None else "Недоступно"
        gpu_temp = f"{gpu_temp:.1f}°C" if gpu_temp is not None else "Недоступно"
        gpu_load = f"{gpu_load:.1f}%" if gpu_load is not None else "Недоступно"
        ram_load = f"{ram_load:.1f}%" if ram_load is not None else "Недоступно"
        now = datetime.now()

        # Вывод в одну строку
        output = (f"Readings from the main PC sensors ({now.strftime('%H:%M:%S')}): \nCPU: {cpu_temp}, {cpu_load}; \nGPU: {gpu_temp}, {gpu_load}; \nRAM: {ram_load}")
        
        return output
    
    except Exception as e:
        logger.error(f"Error: {str(e)}. Make sure OpenHardwareMonitor is running.")
        return f"Error: {str(e)}. Make sure OpenHardwareMonitor is running."
    
# УПРАВЛЕНИЕ ПК, МЫШЬ, КЛАВИАТУРА 

def get_windows_layout():
    """
    Возвращает текущую раскладку клавиатуры в Windows.
    Возвращает строку вроде "ENG","RUS" и прочее.
    """
    if platform.system() != "Windows":
        return "Not a Windows system"

    # Словарь популярных раскладок. Полный список можно найти по запросу "Windows Language Code Identifier"
    layouts = {
        0x409: "ENG", 0x419: "RUS", 0x407: "GER",
        0x40C: "FRA", 0x410: "ITA", 0x411: "JPN", 
        0x412: "KOR", 0x804: "CHN" 
    }

    # Загружаем библиотеку user32.dll
    user32 = ctypes.WinDLL('user32', use_last_error=True)
    hwnd = user32.GetForegroundWindow()
    thread_id = user32.GetWindowThreadProcessId(hwnd, None)
    layout_id = user32.GetKeyboardLayout(thread_id)
    language_id = layout_id & 0xFFFF

    logger.debug(layouts.get(language_id, f"Unknown layout (ID: {hex(language_id)})"))
    return layouts.get(language_id, f"Unknown layout (ID: {hex(language_id)})")

def move_mouse(x, y):
    "Двигает мышь в указанном направлении."
    pyautogui.moveTo(x, y, duration=0.05)
    logger.debug(f"The mouse is moved to coordinates: {x}, {y}")
    return f"The mouse is moved to coordinates: {x}, {y}"

def current_mouse_coordinates():
    "Определяет текущие координаты мыши."
    current_position = pyautogui.position()
    logger.debug(f"The mouse is currently at X={current_position.x}, Y={current_position.y}")
    return f"The mouse is currently at X={current_position.x}, Y={current_position.y}"

def click_mouse(button='left', clicks=1, interval=0.1):
    """Кликнуть мышью. Левой, правой, одинарный, двойной - на выбор."""
    pyautogui.click(button=button, clicks=clicks, interval=interval)
    logger.debug(f"Performed {clicks} click(s) with the {button} mouse button.")
    return f"Performed {clicks} click(s) with the {button} mouse button."

def scroll_mouse(amount):
    """Скроллит вверх (положительное число) или вниз (отрицательное)."""
    pyautogui.scroll(amount)
    direction = "up" if amount > 0 else "down"
    logger.debug(f"Scrolled {abs(amount)} units {direction}.")
    return f"Scrolled {abs(amount)} units {direction}."

def drag_mouse(x_to, y_to, duration=0.5):
    """Тащит мышь из текущей позиции в точку (x, y), как будто что-то выделяет."""
    pyautogui.dragTo(x_to, y_to, duration=duration)
    logger.debug(f"Dragged mouse to {x_to}, {y_to}.")
    return f"Dragged mouse to {x_to}, {y_to}."
    
def press_hotkey(*keys):
    """Нажимает любое количество горячих клавиш. Например: ('ctrl', 'shift', 'esc')"""
    pyautogui.hotkey(*keys)
    logger.debug(f"Hotkey pressed: {' + '.join(keys)}")
    return f"Hotkey pressed: {' + '.join(keys)}"

def copy_to_clipboard(text):
    """Копирует любой текст в буфен обмена."""
    pyperclip.copy(text)
    logger.debug(f"Text '{text}' copied to clipboard.")
    return f"Text '{text}' copied to clipboard."

def write_text(text, attempts=0):
    """Печатает любой текст, даже на эльфийском."""
    keyboard.write(text)

def system_command(command):
    """Выполняет системные команды. Выключение, перезагрузка. ОПАСНО."""
    # Примеры команд для Windows:
    # 'shutdown /s /t 1' - выключить пк через 1 секунду, 'shutdown /r /t 1' - перезагрузить пк через 1 секунду, 'rundll32.exe powrprof.dll,SetSuspendState 0,1,0' - отправить в спящий ре'Проверка.'жим
    os.system(command)
    logger.info(f"Executing system command: {command}.")
    return f"Executing system command: {command}."

# --- ОКНА, ПРОГРАММЫ, ПРИЛОЖЕНИЯ ----

def get_filtered_processes():
    """Сканирует систему и возвращает только полезный список процессов, отфильтровав все ненужные/системные."""
    # Сюда кладем все системные процессы, которые нам нужны
    system_processes_blacklist = [
        "svchost.exe", "lsass.exe", "csrss.exe", "wininit.exe", "services.exe", "winlogon.exe", "dwm.exe", "spoolsv.exe",
        "explorer.exe", "rundll32.exe", "ctfmon.exe", "fontdrvhost.exe", "conhost.exe", "sihost.exe", "taskhostw.exe", "RuntimeBroker.exe",
        "ApplicationFrameHost.exe", "SearchHost.exe", "ShellExperienceHost.exe", "StartMenuExperienceHost.exe", "SystemSettings.exe", "backgroundTaskHost.exe",
        "unsecapp.exe", "System", "System Idle Process", "SecurityHealthSystray.exe", "nvcontainer.exe", "steamwebhelper.exe", "lghub_agent.exe", 
        "msedgewebview2.exe", "OneDrive.Sync.Service.exe", "CrossDeviceResume.exe", "LockApp.exe", "ShellHost.exe", "UserOOBEBroker.exe",
        "WebViewHost.exe", "WidgetService.exe", "Widgets.exe", "XboxPcApp.exe", "XboxPcAppFT.exe", "XboxPcTray.exe", "lghub_system_tray.exe",
        "ruff.exe", "winws.exe"
    ]
    filtered_list = []

    # Получаем имя текущего пользователя, чтобы отсеять процессы других юзеров
    current_user = os.getlogin()

    for process in psutil.process_iter(['pid', 'name', 'username']):
        try:
            proc_info = process.info
            proc_name = proc_info['name']
            proc_user = proc_info['username']

            if not proc_user: # Отсеиваем процессы, у которых нет имени пользователя (обычно это системные)
                continue
            if current_user not in proc_user and 'SYSTEM' not in proc_user: # Оставляем только процессы текущего пользователя
                continue
            if proc_name.lower() in [p.lower() for p in system_processes_blacklist]: # Отсеиваем всё из нашего чёрного списка (без учёта регистра)
                continue

            # Если процесс прошёл все круги ада, добавляем его в список
            filtered_list.append(proc_name)

        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
            pass
    
    # Возвращаем уникальный список, чтобы не было дубликатов
    # (например, 10 процессов chrome.exe превратятся в один)
    logger.debug(f"Current processes in system: {sorted(list(set(filtered_list)))}")
    return f"Current processes in system: {sorted(list(set(filtered_list)))}"

def currently_open_windows():
    """Возвращает текущие окна, которые открыты."""
    titles = []
    all_titles = gw.getAllTitles()
    for title in all_titles:
        if title: # Игнорируем пустые заголовки
            titles.append(title)
    return titles
    
def manage_window(title, action='activate'):
    """Находит окно по заголовку и дает возможность провести разные команды: activate, minimize, maximize, close."""
    try:
        # Ищем окно, заголовок которого СОДЕРЖИТ указанный текст
        windows = gw.getWindowsWithTitle(title)
        if windows:
            win = windows[0]
            if action == 'activate':
                win.activate()
            elif action == 'minimize':
                win.minimize()
            elif action == 'maximize':
                win.maximize()
            elif action == 'close':
                win.close()
            logger.debug(f"Window '{title}' action '{action}' executed.")
            return f"Window '{title}' action '{action}' executed."
        else:
            logger.info(f"Window with title '{title}' not found.")
            return f"Window with title '{title}' not found."
    except IndexError:
        logger.error(f"ERROR: No window with title '{title}' found.")
        return f"ERROR: No window with title '{title}' found."
    except Exception as e:
        logger.error(f"An error occurred: {str(e)}")
        return f"An error occurred: {str(e)}"
    
# --- УПРАВЛЕНИЯ ПРОГРАММАМИ И ПРИЛОЖЕНИЯМИ ---

def open_program(path_to_exe):
    """Открывает программу или файл по указанному пути."""
    try:
        os.startfile(path_to_exe)
        return f"Starting the program at {path_to_exe}."
    except Exception as e:
        return f"Failed to start the program: {str(e)}"
    
def kill_process_by_name(process_name):
    """Находит и безжалостно убивает процесс по его имени."""
    # /f - force, /im - image name
    os.system(f"taskkill /f /im {process_name}") 
    logger.info(f"Sent a kill command to {process_name}.")
    return f"Sent a kill command to {process_name}."



if __name__ == "__main__":
    import time  # noqa: F401
    get_system_volume()
    time.sleep(2)
    get_system_metrics()



========================================
# Содержимое файла: assistant_tools/skills_diagrams.py
========================================

# skills_diagrams.py
get_weather_scheme = {
    "name": "get_weather", # ВАЖНО: ИМЯ ДОЛЖНО СОВПАДАТЬ С ФУНКЦИЕЙ PYTHON
    "description": "Find the current weather in the specified city. This is necessary to answer weather questions with up-to-date data. If no city is specified, Lipetsk is the default location.",
    "parameters": {
        "type": "object",
        "properties": {
            "city_name": {
                "type": "string",
                "description": "The city for which the weather is needed. For example: Moscow.",
            },
        },
    },
}

search_in_google_scheme = {
    "name": "search_in_google",
    "description": "Searches for the given query in a search engine and opens a browser tab. Use this if you need to Google something or open a tab.",
    "parameters": {
        "type": "object",
        "properties": {
            "search_query": {
                "type": "string",
                "description": "Search query. For example: Who is Elon Musk",
            },
        },
    },
}

get_time_scheme = {
    "name": "get_time",
    "description": "Gets the current actual time.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}

get_date_scheme = {
    "name": "get_date",
    "description": "Gets the current actual date.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}


make_screenshot_scheme = {
    "name": "make_screenshot",
    "description": "Takes a screenshot of the user's home screen and saves it to a file. Returns JSON with the path to the created file.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}

save_to_memory_scheme = {
    "name": "save_to_memory",
    "description": "Saves a new fact or piece of information to Vega's long-term memory. Use this when the user provides important new information about themselves, their plans, projects, or asks you to remember something.",
    "parameters": {
        "type": "object",
        "properties": {
            "text": {
                "type": "string",
                "description": "The specific, concise fact to be saved. For example: 'The user's dog is named Rex.' or 'The user is working on a post-apocalyptic car combat game.'",
            },
        },
        "required": ["text"]
    },
}

lock_pc_scheme = {
    "name": "lock_pc",
    "description": "Locks the user's workstation.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}


get_windows_layout_scheme = {
    "name": "get_windows_layout",
    "description": "Returns the current keyboard layout in Windows. Returns a string such as 'ENG', 'RUS', and so on.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}

move_mouse_scheme = {
    "name": "move_mouse",
    "description": "Moves the mouse cursor to the specified X and Y coordinates on the screen.",
    "parameters": {
        "type": "object",
        "properties": {
            "x": {
                "type": "integer",
                "description": "The X-coordinate to move the mouse to."
            },
            "y": {
                "type": "integer",
                "description": "The Y-coordinate to move the mouse to."
            }
        },
        "required": ["x", "y"]
    }
}

current_mouse_coordinates_scheme = {
    "name": "current_mouse_coordinates",
    "description": "Gets the current X and Y coordinates of the mouse cursor.",
    "parameters": {
        "type": "object",
        "properties": {}
    }
}

click_mouse_scheme = {
    "name": "click_mouse",
    "description": "Performs a mouse click. Can be left, right, middle, single, double, etc.",
    "parameters": {
        "type": "object",
        "properties": {
            "button": {
                "type": "string",
                "description": "The mouse button to click: 'left', 'right', or 'middle'. Default is 'left'."
            },
            "clicks": {
                "type": "integer",
                "description": "The number of times to click. Default is 1."
            }
        }
    }
}

scroll_mouse_scheme = {
    "name": "scroll_mouse",
    "description": "Scrolls the mouse wheel up or down.",
    "parameters": {
        "type": "object",
        "properties": {
            "amount": {
                "type": "integer",
                "description": "The number of units to scroll. Positive for up, negative for down."
            }
        },
        "required": ["amount"]
    }
}

drag_mouse_scheme = {
    "name": "drag_mouse",
    "description": "Drags the mouse from its current position to the specified X and Y coordinates. Useful for selecting text or moving items.",
    "parameters": {
        "type": "object",
        "properties": {
            "x_to": {
                "type": "integer",
                "description": "The destination X-coordinate for the drag."
            },
            "y_to": {
                "type": "integer",
                "description": "The destination Y-coordinate for the drag."
            }
        },
        "required": ["x_to", "y_to"]
    }
}

press_hotkey_scheme = {
    "name": "press_hotkey",
    "description": "Presses a combination of keyboard keys simultaneously. For example, ('ctrl', 'c') to copy.",
    "parameters": {
        "type": "object",
        "properties": {
            "keys": {
                "type": "array",
                "items": {
                    "type": "string"
                },
                "description": "A list of keys to press together, for example: ['alt', 'f4']"
            }
        },
        "required": ["keys"]
    }
}

copy_to_clipboard_scheme = {
    "name": "copy_to_clipboard",
    "description": "Copies the given text to the system clipboard.",
    "parameters": {
        "type": "object",
        "properties": {
            "text": {
                "type": "string",
                "description": "The text to be copied."
            }
        },
        "required": ["text"]
    }
}

write_text_scheme = {
    "name": "write_text",
    "description": "Types out the given text in the currently active window. Works with any language.",
    "parameters": {
        "type": "object",
        "properties": {
            "text": {
                "type": "string",
                "description": "The text to be typed."
            }
        },
        "required": ["text"]
    }
}

system_command_scheme = {
    "name": "system_command",
    "description": "Executes a system command, such as shutdown or restart. EXTREMELY DANGEROUS.",
    "parameters": {
        "type": "object",
        "properties": {
            "command": {
                "type": "string",
                "description": "The system command to execute. For Windows: 'shutdown /s /t 1' for shutdown, 'shutdown /r /t 1' for restart."
            }
        },
        "required": ["command"]
    }
}

get_filtered_processes_scheme = {
    "name": "get_filtered_processes",
    "description": "Returns a clean list of user-run applications, filtering out system processes.",
    "parameters": {
        "type": "object",
        "properties": {}
    }
}

currently_open_windows_scheme = {
    "name": "currently_open_windows",
    "description": "Returns a list of titles of all currently open windows.",
    "parameters": {
        "type": "object",
        "properties": {}
    }
}

manage_window_scheme = {
    "name": "manage_window",
    "description": "Finds a window by its title and performs an action on it.",
    "parameters": {
        "type": "object",
        "properties": {
            "title": {
                "type": "string",
                "description": "The title (or part of the title) of the window to manage. For example: 'foobar2000'."
            },
            "action": {
                "type": "string",
                "description": "The action to perform: 'activate', 'minimize', 'maximize', or 'close'. Default is 'activate'."
            }
        },
        "required": ["title"]
    }
}

open_program_scheme = {
    "name": "open_program",
    "description": "Opens a program or file using its full path.",
    "parameters": {
        "type": "object",
        "properties": {
            "path_to_exe": {
                "type": "string",
                "description": "The full path to the executable or file to open. For example: 'C:\\Program Files\\...\\chrome.exe'."
            }
        },
        "required": ["path_to_exe"]
    }
}


kill_process_by_name_scheme = {
    "name": "kill_process_by_name",
    "description": "Forcibly terminates a running process by its name (e.g., 'chrome.exe'). DANGEROUS.",
    "parameters": {
        "type": "object",
        "properties": {
            "process_name": {
                "type": "string",
                "description": "The name of the process executable to kill."
            }
        },
        "required": ["process_name"]
    }
}

get_system_volume_scheme = {
    "name": "get_system_volume",
    "description": "Получает текущее значение громкости системы в процентах.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}

set_system_volume_scheme = {
    "name": "set_system_volume",
    "description": "Устанавливает абсолютное значение громкости системы. Принимает значение от 0 до 100.",
    "parameters": {
        "type": "object",
        "properties": {
            "level_volume": {
                "type": "integer",
                "description": "Целевой уровень громкости в процентах (например, 50).",
            },
        },
        "required": ["level_volume"] # Явно указываем, что этот параметр обязателен
    },
}

decrease_volume_scheme = {
    "name": "decrease_volume",
    "description": "Уменьшает громкость системы на указанное значение. По умолчанию уменьшает на 10%.", 
    "parameters": {
        "type": "object",
        "properties": {
            "amount": {
                "type": "integer",
                "description": "Значение в процентах, на которое нужно уменьшить громкость (например, 15).",
            },
        },
        # "required" здесь не нужен, так как у amount есть значение по умолчанию (он опциональный)
    },
}

increase_volume_scheme = {
    "name": "increase_volume",
    "description": "Увеличивает громкость системы на указанное значение. По умолчанию увеличивает на 10%.",
    "parameters": {
        "type": "object",
        "properties": {
            "amount": { 
                "type": "integer",
                "description": "Значение в процентах, на которое нужно увеличить громкость (например, 20).",
            },
        },
    },
}

get_habr_news_scheme = {
    "name": "get_habr_news",
    "description": "Receives the latest news from Habr.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}

get_system_metrics_scheme = {
    "name": "get_system_metrics",
    "description": "Gets the current load, temperature of the video card, processor and RAM in the system.",
    "parameters": {
        "type": "object",
        "properties": {}
    },
}


========================================
# Содержимое файла: assistant_tools/utils.py
========================================

# utils.py
import random 
import threading
import pygame
import time

SOUNDS = {
    'system_startup': ('sounds/system_startup1.mp3',),
    'select': ('sounds/select1.mp3',),
    'confirmation': ('sounds/confirmation1.mp3',),
    'processing': ('sounds/processing1.mp3',),
    'hard_processing': ('sounds/hard_processing1.mp3',),
    'search': ('sounds/search1.mp3',),
    'mechanical_movement': ('mechanical_movement1.mp3',),
    'lauch_vector_database': ('sounds/lauch_vector_database1.mp3',), 
    'start_embedding_model': ('sounds/start_embedding_model1.mp3',), 

    'error': ('sounds/error1.mp3', 'sounds/error2.mp3', 'sounds/error3.mp3', 'sounds/error4.mp3', 'sounds/error5.mp3', 'sounds/error6.mp3',), # ПОНАСТАВЛЯТЬ ЗВУКИ
}

try:
    pygame.mixer.init()
    print("Pygame mixer initialized successfully.")
except pygame.error as e:
    print(f"Fatal error: Could not initialize pygame mixer. Sound will be disabled. Error: {e}")
    pygame = None # Отключаем pygame, если он не смог запуститься

def _play_sound_worker(sound_name: str):
    if sound_name in SOUNDS:
        sounds = SOUNDS[sound_name] 
        pygame.mixer.music.load(random.choice(sounds))
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy(): # Ждать окончания
            time.sleep(1)
    else:
        print("Error: Non-existent sound selected for function 'play_sfx()'.")

def play_sfx(sound_name: str):
    if not sound_name:
        return

    sound_worker_thread = threading.Thread(target=_play_sound_worker, kwargs={"sound_name": sound_name,}) # Создаем, собственно, отдельный поток
    sound_worker_thread.start()



========================================
# Содержимое файла: assistant_vector_database/database.py
========================================

# database.py
from assistant_tools.utils import play_sfx
from langchain_huggingface import HuggingFaceEmbeddings 
from langchain_chroma import Chroma  
from datetime import datetime
from assistant_event_bus.event_bus import subscribe, publish
import uuid
from assistant_general import general_settings as general_settings

# Эмбеддинг модель, чтобы превращать запросы пользователя в векторы и искать похожие в базе данных
print("Initialization of the embedding model.")
play_sfx("start_embedding_model")
embedding_model = HuggingFaceEmbeddings(
    model_name = "BAAI/bge-m3", # Можно выбрать intfloat/multilingual-e5-large - она более быстрая, но менее точная
    encode_kwargs = {"normalize_embeddings": True} # при создании векторов из текста делать нормализацию
    ) 

# Векторная база данных
print("Initialization of vector database.")
play_sfx("lauch_vector_database")
vectorstore = Chroma(
    collection_name="assistant_database", # Называем коллекцию внутри базы данных так
    embedding_function=embedding_model, # # Прикрепление модели эмбеддингов
    persist_directory="""./assistant_chroma_db""", # Сохранять в эту папку
    )

def add_new_memory(new_text: str):
    """Принимает текст, генерирует для него уникальный ID, добавляет текущую дату в метаданные и сохраняет в Chroma."""
    current_date = datetime.now().strftime("%d.%m.%Y")
    record_id = str(uuid.uuid4()) # Генерируем уникальный ID для записи
    
    metadata = {"creation_date": current_date}

    # Добавляем текст, его ID и его метаданные в базу.
    # Важно: add_texts принимает списки, поэтому оборачиваем все в []
    vectorstore.add_texts(
        texts=[new_text], 
        ids=[record_id], 
        metadatas=[metadata]
    )
    
    print(f"New entry added to memory: '{new_text}'")

def find_records_in_database(**kwargs):
    """Ищет записи в векторной базе данных и форматирует результат в читаемую строку."""

    # Если запрос пуст
    query = kwargs.get('query')
    if not query:
        return

    results_with_scores = vectorstore.similarity_search_with_score(query, k=general_settings.NUM_RECORDS_FROM_DATABASE)

    # Если база пуста
    if not results_with_scores:
        result = {"original_query": query, "database_context": "No relevant records were found in the database."}
        print("No relevant records were found in the database.")
        publish("USER_SPEECH_AND_RECORDS_FOUND_IN_DB", result)
        return 
    
    formatted_lines = []

    print("\nSearching for records in the database:")
    
    for document, score in results_with_scores:
        if score <= general_settings.SIMILARITY_THRESHOLD:
            # Если запись ДОСТАТОЧНО похожа, обрабатываем ее
            print(f"Record is relevant enough (score: {score:.2f}, threshold: {general_settings.SIMILARITY_THRESHOLD})")
            
            date = document.metadata.get('creation_date', 'Date not found')
            text = document.page_content
            
            # Добавим оценку в вывод для наглядности
            formatted_lines.append(f"[Score: {score:.2f}] {date}: {text}")
        else:
            # Если запись НЕдостаточно похожа, мы можем ее проигнорировать
            print(f"Record is NOT relevant enough (score: {score:.2f}, threshold: {general_settings.SIMILARITY_THRESHOLD}). Skipping.")
            # Мы можем либо ничего не делать, либо добавить сообщение об этом
            # formatted_lines.append(f"[Not relevant enough, score: {score:.2f}]") 

    # Если после фильтрации не осталось релевантных записей
    if not formatted_lines:
        final_string = "Found some records, but none were similar enough to the query."
    else:
        # Соединяем только релевантные строки
        final_string = "\n".join(formatted_lines)

    result = {"original_query": query, "database_context": final_string}
    print(f"\nFound records in database for query '{query}': \n{final_string}")
    
    publish("USER_SPEECH_AND_RECORDS_FOUND_IN_DB", result)


def initialize_database():
    subscribe("USER_SPEECH", find_records_in_database)




========================================
# Содержимое файла: assistant_vector_database/inspect_memory.py
========================================

# inspect_memory.py
import chromadb

client = chromadb.PersistentClient(path="assistant_chroma_db") 

try:
    collection_name = "assistant_database"
    collection = client.get_collection(name=collection_name)
    print(f"Successfully connected to collection: '{collection_name}'")

except Exception as e:
    print(f"Error connecting to collection: {e}")
    print("Available collections:", [col.name for col in client.list_collections()])
    exit()

try:
    all_records = collection.get(
        include=["metadatas", "documents"]
    )

    num_records = len(all_records['ids'])
    print(f"\n--- Found {num_records} records in V.E.G.A. memory ---\n")

    for i in range(num_records):
        record_id = all_records['ids'][i]
        document = all_records['documents'][i]
        metadata = all_records['metadatas'][i]

        print(f"--- Record ID: {record_id} ---")
        print(f"Document (Text): {document}")
        print(f"Metadata: {metadata}")
        print("-" * 20 + "\n")

except Exception as e:
    print(f"An error occurred while fetching records: {e}")


========================================
# Содержимое файла: main.py
========================================

# main.py
import threading
import time
from assistant_brain.brain import initialize_brain, generate_general_greeting
from assistant_output.voice_output_eng import SpeechModuleENG
from assistant_output.voice_output_rus import SpeechModuleRUS
from assistant_tools.utils import play_sfx
from assistant_vector_database.database import initialize_database
from assistant_general.general_settings import choose_language

play_sfx('hard_processing')

initialize_brain() # вызывает subscribe("USER_SPEECH", generate_response), чтобы не импортировать сразу весь brain
initialize_database()

while True: 
    print("\nPlease, choose language for V.E.G.A.")
    command = input("'1' - russian, '2' - english, '3' - exit \n\n>> ")

    if command == "1": # Если русский язык
        speech_module = SpeechModuleRUS()
        speech_module.start()
        choose_language("RUSSIAN")
        break

    if command == "2": # Если английский язык 
        speech_module = SpeechModuleENG()
        speech_module.start()
        choose_language("ENGLISH")
        break

    if command == "3":
        print("Exit from the V.E.G.A. system.")
        exit()

    else:
        print("Invalid mode. Please try again.")

generate_general_greeting()

while True:
    input_mode = input("\nSelect the input mode ('1' - voice, '2' - text, '3' - output): ")
    if input_mode == "1":
        from assistant_input.voice_input import SpeechListener
        play_sfx("select")
        speech_listener = SpeechListener()
        speech_listener.start()
        break 

    elif input_mode == "2":
        from assistant_input.text_input import text_input_loop
        play_sfx("select")
        text_thread = threading.Thread(target=text_input_loop)
        text_thread.daemon = True
        text_thread.start()
        break 

    elif input_mode == "3":
        print("Logout from the V.E.G.A. system")
        exit()

    else:
        print("Incorrect mode. Please try again.")

# НАДО СДЕЛАТЬ: фоновые задачи (а также tasks_completed_today.json), интерфейс

# Централизованная Обработка Ошибок: Сейчас try/except в каждой функции. Можно подумать над созданием декоратора, который будет оборачивать все "навыки", логировать ошибки и возвращать стандартизированный ответ в случае сбоя 

# Для background_tasks.py идеально подойдет библиотека вроде APScheduler        
try:
    while True:
        time.sleep(1)

        # def generate_briefing():
        #     """Генерирует и озвучивает утренний/дневной брифинг."""

        # Парсинг новостей/данных (data_harvester.py):
        #Что делает: Раз в час "ходит" на выбранные сайты (новостные агрегаторы, Reddit, Hacker News, GitHub Trending) и собирает заголовки по ключевым для тебя темам (AI, Python, кибербезопасность, квантовая физика)

        # Анализ погоды (weather_agent.py):
        # Что делает: Через API погоды (например, OpenWeatherMap) проверяет прогноз на сегодня и завтра.

        # Автоматизация рутины (task_automator.py):
        # Что делает: Выполняет простые скрипты по расписанию или триггеру. Например, в полночь запускает скрипт для очистки временных файлов или создания бэкапа важных папок.

        # Генератор случайных взаимодействий (serendipity_engine.py):
        # Что делает: Это реализация TODO. В случайные моменты времени (не чаще раза в час, чтобы не раздражать) Вега выдает что-то не связанное с работой:
        # Интересный факт: "Знаете ли вы, что в момент Большого взрыва Вселенная была горячее, чем ядро Солнца, и имела плотность, превышающую плотность атомного ядра?"
        # "Анализ вашего плейлиста показывает 87% совпадение с 'грустными песнями для одиноких вечеров'. Система работает в штатном режиме."
        # "Если бы вы могли добавить мне одну новую способность прямо сейчас, что бы это было?"

        # Системный мониторинг в реальном времени
        # Как это работает: Вместо того чтобы Вега просто говорила "Загрузка CPU 75%", она в реальном времени строит и обновляет линейный график, показывающий динамику загрузки CPU за последние 60 секунд.

except KeyboardInterrupt:
    print("\nThe program is ending.")



========================================
# Содержимое файла: systemic_tools/systemic_skills.py
========================================

# systemic_skills.py

import json

def read_json(filename: str):
    """Читает JSON-файл. Если файла нет или он поврежден, создает его с содержимым по умолчанию и возвращает его."""
    try:
        with open(filename, "r", encoding="utf-8") as file:
            return json.load(file)
    except (FileNotFoundError, json.JSONDecodeError):
        # Если файла нет или он пустой/битый
        print(f"Файл '{filename}' не найден или поврежден.")
     
def write_json(filename: str, data: dict):
    try:
        with open(filename, "w", encoding="utf-8") as file:
            json.dump(data, file, indent=4)
    except Exception as e:
        return f"Error writing to json file: {e}"


========================================
# Содержимое файла: tests/find_path.py
========================================

import sys

print(sys.executable)




========================================
# Содержимое файла: tests/just_another_test.py
========================================

# import os
# from fuzzywuzzy import process

# MUSIC_LIBRARY_PATH = "C:\\Users\\ivanc\\Desktop\\Project_V.E.G.A\\VEGA_core\\assistant_music\\music"

# def find_best_match(song_query: str):
#     """Проходит по всем файлам, находит лучшее совпадение и возвращает его."""
    
#     all_tracks_names = []
    
#     # ПРАВИЛЬНЫЙ СПОСОБ использования os.walk
#     for root, dirs, files in os.walk(MUSIC_LIBRARY_PATH): # В os.walk: root — путь к текущей папке; dirs — список названий подпапок в этой папке; files — список названий файлов в этой папке
#         for filename in files:
            
#             clean_name = os.path.splitext(filename)[0]
#             all_tracks_names.append(clean_name)

#     print("--- Список для поиска ---")
#     print(all_tracks_names)
#     print("\n")

#     best_match = process.extractOne(song_query, all_tracks_names)
#     print(f"Результат поиска: {best_match}")
#     return best_match

# while True:
#     song = input("Введите песню для поиска: ")
#     if not song:
#         break
#     find_best_match(song)






import requests

try:
    print("Пытаюсь подключиться к Google...")
    response = requests.get('https://www.google.com', timeout=10)
    print(f"Успех! Статус-код: {response.status_code}")
    print("Значит, базовый выход в интернет из Python работает.")
except Exception as e:
    print("\nПИЗДЕЦ! Опять ошибка!")
    print(f"Не удалось подключиться. Ошибка: {e}")


========================================
# Содержимое файла: tests/test!.py
========================================

from ctypes import cast, POINTER
from comtypes import CLSCTX_ALL
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume

def get_system_volume() -> int:
    """Возвращает текущую системную громкость в процентах (от 0 до 100)."""
    try:
        # Находим аудио устройство
        devices = AudioUtilities.GetSpeakers()
        interface = devices.Activate(
            IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
        volume_control = cast(interface, POINTER(IAudioEndpointVolume))
        
        # Получаем громкость в виде скаляра (от 0.0 до 1.0)
        current_volume_scalar = volume_control.GetMasterVolumeLevelScalar()
        
        # Переводим скаляр в проценты
        current_volume_percent = int(current_volume_scalar * 100)

        print(f"Current volume: {current_volume_percent}")
        return f"Current volume: {current_volume_percent}"
    except Exception as e:
        return f"Ошибка при получении информации о текущей громкости: {e}"

def set_system_volume(level: int):
    """Принимает, блядь, число от 0 до 100 и выставляет такую системную громкость."""
    if not 0 <= level <= 100:
        print(f"ТЫ ЧТО, БЛЯДЬ, ТУПОЙ? Громкость должна быть от 0 до 100, а не {level}!")
        return

    try:
        # Находим аудио устройство
        devices = AudioUtilities.GetSpeakers()
        interface = devices.Activate(
            IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
        volume_control = cast(interface, POINTER(IAudioEndpointVolume))
        
        # Переводим проценты в скаляр от 0.0 до 1.0
        target_volume_scalar = level / 100.0
        
        # Выставляем  громкость
        volume_control.SetMasterVolumeLevelScalar(target_volume_scalar, None)
        
        print(f"Volume changed to {level}%.")
        return f"Volume changed to {level}%."
    except Exception as e:
        print(f"Error when changing volume: {e}")
        return f"Error when changing volume: {e}"

if __name__ == "__main__":
    import time  # noqa: F401
    get_system_volume()
    time.sleep(2)
    set_system_volume(55)




========================================
# Содержимое файла: tests/test_ocr.py
========================================

import easyocr
import pytesseract
from PIL import Image, ImageEnhance
import pyautogui
import os
import time
import cv2
from paddleocr import PaddleOCR

pytesseract.pytesseract.tesseract_cmd = r'C:\Users\ivanc\Desktop\Project_V.E.G.A\Tesseract-OCR\tesseract.exe'

def make_screenshot():
    filename = "screenshot.png"
    try:
        # Делаем скриншот
        screenshot = pyautogui.screenshot()
        
        # Конвертируем скриншот pyautogui в PIL Image
        screenshot_pil = screenshot  # pyautogui.screenshot() возвращает объект, совместимый с PIL
        
        # Убедимся, что это объект PIL.Image
        if not isinstance(screenshot_pil, Image.Image):
            screenshot_pil = Image.frombytes('RGB', screenshot.size, screenshot.rgb)
        
        # Улучшаем резкость (опционально)
        enhancer = ImageEnhance.Sharpness(screenshot_pil)
        screenshot_pil = enhancer.enhance(2.0)  # Увеличение резкости (значение от 0 до 2)

        # Масштабирование изображения для увеличения разрешения
        new_size = (int(screenshot_pil.width * 2), int(screenshot_pil.height * 2))
        screenshot_pil = screenshot_pil.resize(new_size, Image.Resampling.LANCZOS)

        # Сохраняем с высоким качеством
        screenshot_pil.save(filename, quality=95, optimize=True)
        
        return {"status": "success", "file_path": os.path.abspath(filename)}
    except Exception as e:
        print(f"Ошибка создания скриншота: {str(e)}")
        return {"status": "error", "message": str(e)}

def preprocess_image(image_path):
    try:
        image = cv2.imread(image_path)
        if image is None:
            raise FileNotFoundError(f"Не удалось загрузить изображение: {image_path}")
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        cv2.imwrite('processed_screenshot.png', gray)
        return gray
    except Exception as e:
        print(f"Ошибка предобработки изображения: {str(e)}")
        return None

def read_text_tesseract():
    try:
        result = make_screenshot()
        if result["status"] == "error":
            print(f"Ошибка: {result['message']}")
            return
        image_path = result["file_path"]
        
        # Предобработка изображения
        processed_image = preprocess_image(image_path)
        if processed_image is None:
            print("Не удалось обработать изображение.")
            return
        
        # Распознавание текста с оптимизированными параметрами
        text = pytesseract.image_to_string(processed_image, lang='rus+eng', config='--oem 1 --psm 6')
        print("Извлеченный текст (Pytesseract):")
        print(text if text.strip() else "Текст не распознан.")

    except Exception as e:
        print(f"Ошибка при распознавании текста: {str(e)}")

def read_text_easyocr():
    try:
        result = make_screenshot()
        if result["status"] == "error":
            print(f"Ошибка: {result['message']}")
            return
        
        print("Инициализация EasyOCR...")
        reader = easyocr.Reader(['ru', 'en'])
        result = reader.readtext('screenshot.png')
        print("Извлеченный текст (EasyOCR):")
        for detection in result:
            print(detection[1])  # detection[1] — извлеченный текст
    except Exception as e:
        print(f"Ошибка при распознавании текста: {str(e)}")

def read_text_paddleocr():
    try:
        result = make_screenshot()
        if result["status"] == "error":
            print(f"Ошибка: {result['message']}")
            return
        
        print("Инициализация PaddleOCR...")
        ocr = PaddleOCR(use_angle_cls=True, lang='ru')
        result = ocr.ocr('screenshot.png', cls=True)
        print("Извлеченный текст (PaddleOCR):")
        for line in result[0]:  # PaddleOCR возвращает список результатов
            print(line[1][0])  # Текст находится во втором элементе кортежа
    except Exception as e:
        print(f"Ошибка при распознавании текста: {str(e)}")

def print_play_text(model):
    print(f"Запуск {model} через 3 секунды...")
    time.sleep(3)
    print("Запуск.")

if __name__ == "__main__":
    while True:
        print("\n\n'1' - Pytesseract, '2' - EasyOCR, '3' - PaddleOCR, '4' - выйти.")
        command = input("Введите модель компьютерного зрения для проверки: ")

        if command == "1":
            print_play_text("Pytesseract")
            read_text_tesseract()
        elif command == "2":
            print_play_text("EasyOCR")
            read_text_easyocr()
        elif command == "3":
            print_play_text("PaddleOCR")
            read_text_paddleocr()
        elif command == "4":
            print("Выход.")
            break
        else:
            print("Неизвестная команда. Попробуйте снова.")


========================================
# Содержимое файла: vosk_model/vosk-model-ru-0.42/decode.py
========================================

#!/usr/bin/env python3

from vosk import Model, KaldiRecognizer, SetLogLevel
import sys
import os
import wave

SetLogLevel(0)

if len(sys.argv) == 2:
    wf = wave.open(sys.argv[1], "rb")
else:
    wf = wave.open("decoder-test.wav", "rb")

if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != "NONE":
    print ("Audio file must be WAV format mono PCM.")
    exit (1)

model = Model(".")
rec = KaldiRecognizer(model, wf.getframerate())
rec.SetWords(True)

while True:
    data = wf.readframes(4000)
    if len(data) == 0:
        break
    if rec.AcceptWaveform(data):
        print(rec.Result())
    else:
        print(rec.PartialResult())

print(rec.FinalResult())


